# ğŸš€ Snabbstartsguide - VS Code

## Steg-fÃ¶r-steg setup i 5 minuter

### 1. Ã–ppna projektet i VS Code

### 2. Installera Python-beroenden
Ã–ppna en terminal i VS Code (`Ctrl+`` eller `Cmd+``) och kÃ¶r:

```bash
pip install pypdf --break-system-packages
```

Testa att det fungerar:
```bash
python3 server/extract_pdf_text.py --version
```

### 3. Installera Node.js-beroenden
I samma terminal:

```bash
npm install
```

### 4. Starta Ollama
Ã–ppna en **ny terminal** (`Terminal â†’ New Terminal`) och kÃ¶r:

```bash
ollama serve
```

LÃ¥t denna terminal vara Ã¶ppen. I den **fÃ¶rsta terminalen**, ladda ner en modell:

```bash
ollama pull llama3.2
```

### 5. Starta applikationen
I den fÃ¶rsta terminalen:

```bash
npm start
```

### 6. Ã–ppna i webblÃ¤saren
GÃ¥ till: **http://localhost:3000**

## âœ… Checklista

- [ ] Python 3 installerat
- [ ] pypdf installerat
- [ ] Node.js installerat
- [ ] npm dependencies installerade
- [ ] Ollama installerat och igÃ¥ng
- [ ] AI-modell nedladdad
- [ ] Server startad pÃ¥ port 3000

## ğŸ¯ TestanvÃ¤ndning

1. Exportera din LinkedIn-profil:
   - GÃ¥ till LinkedIn â†’ Din profil
   - Klicka pÃ¥ "Mer" â†’ "Spara som PDF"

2. I appen:
   - VÃ¤lj PDF-filen
   - Skriv "Frontend Developer" eller liknande
   - Klicka "Analysera matchningar"

3. VÃ¤nta ~30-60 sekunder fÃ¶r analys av 15 jobb

## ğŸ”§ VS Code Tips

### Rekommenderade extensions
- **ES7+ React/Redux/React-Native snippets** (fÃ¶r JavaScript)
- **Python** (Microsoft)
- **REST Client** (fÃ¶r API-testning)

### Ã–ppna flera terminaler
1. `Ctrl+Shift+`` (eller `Cmd+Shift+``) fÃ¶r ny terminal
2. Terminal 1: Node.js server (`npm start`)
3. Terminal 2: Ollama (`ollama serve`)
4. Terminal 3: Fri fÃ¶r testning/debugging

### Debugging

**Backend:**
1. LÃ¤gg till breakpoints i `server/server.js`
2. Tryck `F5` eller gÃ¥ till Run â†’ Start Debugging
3. VÃ¤lj "Node.js" som environment

**Frontend:**
1. Ã–ppna DevTools i webblÃ¤saren (`F12`)
2. GÃ¥ till Console fÃ¶r loggar
3. GÃ¥ till Network fÃ¶r att se API-anrop

### Live reload
Servern startar om automatiskt om du anvÃ¤nder nodemon:

```bash
npm install -g nodemon
nodemon server/server.js
```

## ğŸ“ Vanliga kommandon

```bash
# Starta server
npm start

# Testa API
curl http://localhost:3000/api/health

# Testa jobbsÃ¶kning
curl "http://localhost:3000/api/test/jobs?q=developer"

# Lista Ollama-modeller
ollama list

# Testa Ollama
curl http://localhost:11434/api/tags

# Se server-loggar (om servern kÃ¶rs)
# Tryck Ctrl+C fÃ¶r att stoppa servern
```

## ğŸ› Snabb felsÃ¶kning

### Portkollision (port 3000 upptagen)
```bash
# Ã„ndra port i server.js eller anvÃ¤nd miljÃ¶variabel
PORT=3001 npm start
```

### Ollama svarar inte
```bash
# Starta om Ollama
pkill ollama
ollama serve
```

### PDF-extraktion fungerar inte
```bash
# Testa manuellt
python3 server/extract_pdf_text.py /path/to/test.pdf

# Om pypdf saknas
pip install pypdf --break-system-packages
```

### Node modules saknas
```bash
# Rensa och installera om
rm -rf node_modules
npm install
```

## ğŸ“Š Prestanda

FÃ¶rvÃ¤ntade tider:
- PDF-extraktion: ~1-2 sekunder
- JobbannonshÃ¤mtning: ~2-3 sekunder
- AI-analys (15 jobb): ~30-60 sekunder
- **Total tid**: ~40-70 sekunder per analys

Tips fÃ¶r snabbare analys:
- AnvÃ¤nd mindre modell: `llama3.2` (snabb) istÃ¤llet fÃ¶r `llama2:13b` (lÃ¥ngsam men bÃ¤ttre)
- Minska antal jobb i `server/jobsearch.js` (Ã¤ndra `limit: 15` till `limit: 10`)

## ğŸ¨ Anpassa appen

### Ã„ndra styling
Redigera: `public/css/style.css`
- CSS-variabler i `:root` fÃ¶r fÃ¤rger
- LinkedIn-inspirerat tema

### Ã„ndra AI-beteende
Redigera: `server/ollama.js`
- Funktion: `createMatchingPrompt()`
- Justera temperature i `analyzeJobMatch()` (0.1 = konsekvent, 0.8 = kreativ)

### Ã„ndra antal jobb
Redigera: `server/jobsearch.js`
- Rad: `limit = 15` â†’ Ã¤ndra till Ã¶nskat antal

## ğŸ“ NÃ¤sta steg

NÃ¤r du Ã¤r bekvÃ¤m med grunderna:
1. LÃ¤s igenom backend-koden i `server/`
2. Experimentera med olika AI-prompts
3. Testa olika Ollama-modeller
4. Anpassa frontend-grÃ¤nssnittet

Lycka till! ğŸš€
